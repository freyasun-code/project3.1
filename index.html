<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Project 3A: Image Warping and Mosaicing</title>
  <style>
    body {
      background-color: #D8C3DD;
      font-family: Arial, sans-serif;
      color: white;
      margin: 0;
      padding: 0;
    }
    nav {
      background: rgba(0, 0, 0, 0.3);
      padding: 10px 20px;
      position: sticky;
      top: 0;
      z-index: 1000;
    }
    nav a {
      color: #ffddff;
      text-decoration: none;
      margin: 0 15px;
      font-weight: bold;
    }
    nav a:hover {
      text-decoration: underline;
    }
    .container {
      width: 90%;
      margin: auto;
      padding: 20px;
    }
    h1 {
      text-align: center;
      margin-top: 20px;
    }
    .section {
      background-color: #D7D3EB; /* 固定浅紫灰色，不透明 */
      padding: 30px;
      margin: 40px 0;
      border-radius: 12px;
    }
    .section h2 {
      color: #ffddff;
      text-align: center;
    }
    img {
      max-width: 100%;
      border-radius: 8px;
    }
    .row {
      display: flex;
      justify-content: center;
      gap: 30px;
      margin: 20px 0;
      flex-wrap: wrap;
    }
    .img-block {
      text-align: center;
    }
    .img-block p {
      margin-top: 8px;
      font-size: 16px;
      text-align: center;
    }
    p {
      text-align: left;
      max-width: 1000px;
      margin: auto;
      margin-bottom: 20px;
      font-size: 18px;
    }
  </style>
</head>

<body>
  <nav>
    <a href="#A1">A.1</a>
    <a href="#A2">A.2</a>
    <a href="#A3">A.3</a>
    <a href="#A4">A.4</a>
    <a href="#B1">B.1</a>
    <a href="#B2">B.2</a>
    <a href="#B3">B.3</a>
    <a href="#B4">B.4</a>
  </nav>

  <div class="container">
    <h1>Project 3A: Image Warping and Mosaicing</h1>
    <p style="text-align:center; font-style:italic;">Freya Sun</p>

<!-- A.1 -->
<div class="section" id="A1">
  <h2>A.1: Shoot the Pictures</h2>
  <p>Here are my three sets of images.</p>

  <div class="row">
    <div class="img-block">
      <img src="tower-left.jpg" alt="tower left" width="350">
      <p>tower-left</p>
    </div>
    <div class="img-block">
      <img src="tower-right.jpg" alt="tower right" width="350">
      <p>tower-right</p>
    </div>
  </div>

  <div class="row">
    <div class="img-block">
      <img src="library-left.jpg" alt="library left" width="300">
      <p>library-left</p>
    </div>
    <div class="img-block">
      <img src="library-middle.jpg" alt="library middle" width="300">
      <p>library-middle</p>
    </div>
    <div class="img-block">
      <img src="library-right.jpg" alt="library right" width="300">
      <p>library-right</p>
    </div>
  </div>

  <div class="row">
    <div class="img-block">
      <img src="street-left.jpg" alt="street left" width="300">
      <p>street-left</p>
    </div>
    <div class="img-block">
      <img src="street-middle.jpg" alt="street middle" width="300">
      <p>street-middle</p>
    </div>
    <div class="img-block">
      <img src="street-right.jpg" alt="street right" width="300">
      <p>street-right</p>
    </div>
  </div>
</div>

<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>A.2: Recovering the Homography</title>

  <!-- MathJax configuration -->

  <script>
  window.MathJax = {
    tex: {
      inlineMath: [['\\(','\\)']],
      displayMath: [['\\[','\\]']]
    },
    options: {
      skipHtmlTags: ['script','noscript','style','textarea','pre','code']
    }
  };
  </script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Basic layout styles -->

  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      line-height: 1.6;
      background-color: #fafafa;
      color: #333;
    }
    h2, h3, h4 {
      color: #003366;
    }
    .section {
      margin-bottom: 60px;
    }
    .row {
      display: flex;
      justify-content: center;
      align-items: flex-start;
      gap: 40px;
      margin-top: 25px;
    }
    .img-block {
      text-align: center;
    }
    img {
      border-radius: 6px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.15);
    }
    pre {
      background: #f4f4f4;
      border-radius: 6px;
      padding: 14px;
      font-family: Consolas, monospace;
      font-size: 14px;
      overflow-x: auto;
    }
  </style>

</head>

<body>

<div class="section" id="A2">
  <h2>A.2: Recovering the Homography</h2>

  <h3>computeH(im1_pts, im2_pts) function:</h3>

  <div style="text-align:center;">
    <pre style="display:inline-block; text-align:left;">
def computeH(src_pts, dst_pts):
    assert src_pts.shape == dst_pts.shape and src_pts.shape[0] >= 4
    num_points = src_pts.shape[0]
    A = []
    b = []
    for i in range(num_points):
        x, y = src_pts[i, :]
        u, v = dst_pts[i, :]
        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y])
        A.append([0, 0, 0, x, y, 1, -v*x, -v*y])
        b.append(u)
        b.append(v)
    A = np.array(A)
    b = np.array(b)
    h, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
    H = np.append(h, 1).reshape(3, 3)
    return H
    </pre>
  </div>

  <h3>Recovered Homography Matrix H:</h3>

  <div style="text-align:center;">
    <pre style="display:inline-block; text-align:center;">
      [  1.82  -0.05 -888.37 ]
      [  0.36   1.50 -404.83 ]
      [  0.00   0.00    1.00 ]
    </pre>
  </div>

  <h3>System of Equations:</h3>

  <p>
    To align one image to another, we need to find a <strong>homography matrix</strong> \( H \) that maps a point 
    \((x, y)\) in the first image to its corresponding point \((u, v)\) in the second image:
  </p>

  <div style="text-align:center;">
    \[
    \lambda
    \begin{bmatrix}
    u \\ v \\ 1
    \end{bmatrix}
    =
    H
    \begin{bmatrix}
    x \\ y \\ 1
    \end{bmatrix}
    \]
  </div>

  <p>where \(\lambda\) is an arbitrary scale factor and \(H\) has 8 degrees of freedom (we set the 9th element to 1).</p>

  <h4>Setting up the Linear System</h4>

  <div style="text-align:center;">
    \[
    u = \frac{h_1 x + h_2 y + h_3}{h_7 x + h_8 y + 1}, \qquad
    v = \frac{h_4 x + h_5 y + h_6}{h_7 x + h_8 y + 1}
    \]
  </div>

  <p>
    Multiplying through by the denominator and rearranging gives two linear equations per correspondence:
  </p>

  <div style="text-align:center;">
    \[
    \begin{cases}
    h_1 x + h_2 y + h_3 - u(h_7 x + h_8 y) = u, \\
    h_4 x + h_5 y + h_6 - v(h_7 x + h_8 y) = v.
    \end{cases}
    \]
  </div>

  <p>
    Written in matrix form (two rows per correspondence):
  </p>

  <div style="text-align:center;">
    \[
    \begin{bmatrix}
    x & y & 1 & 0 & 0 & 0 & -u x & -u y \\
    0 & 0 & 0 & x & y & 1 & -v x & -v y
    \end{bmatrix}
    \begin{bmatrix}
    h_1 \\ h_2 \\ h_3 \\ h_4 \\ h_5 \\ h_6 \\ h_7 \\ h_8
    \end{bmatrix}
    =
    \begin{bmatrix}
    u \\ v
    \end{bmatrix}
    \]
  </div>

  <h4>Solving</h4>

  <p>
    With \(N\) correspondences we have \(2N\) equations, which we can solve via least squares:
  </p>

  <div style="text-align:center;">
    \[
    h = \operatorname*{argmin}_h \|A h - b\|^2
    \]
  </div>

  <p style="text-align:center; font-style:italic;">
    The final 3×3 homography matrix is formed by appending 1 to complete \( H \):
  </p>

  <div style="text-align:center;">
    \[
    H =
    \begin{bmatrix}
    h_1 & h_2 & h_3 \\
    h_4 & h_5 & h_6 \\
    h_7 & h_8 & 1
    \end{bmatrix}
    \]
  </div>

  <h3>Correspondences Visualized on the Images:</h3>

  <div class="row">
    <div class="img-block">
      <img src="im1_points.jpg" alt="image 1 correspondences" width="420">
      <p>Image 1 (Left)</p>
    </div>
    <div class="img-block">
      <img src="im2_points.jpg" alt="image 2 correspondences" width="420">
      <p>Image 2 (Right)</p>
    </div>
  </div>

</div>

</body>
</html>


<!-- A.3 -->

<div class="section" id="A3">
  <h2>A.3: Warp the Images</h2>

  <p>
    After computing the homography matrix \( H \), we can use it to warp an image into the reference frame of another. 
    To do this, we implemented two functions:
  </p>

  <div style="text-align:center;">
    <pre style="display:inline-block; text-align:left;">
imwarped_nn = warpImageNearestNeighbor(im, H)
imwarped_bil = warpImageBilinear(im, H)
    </pre>
  </div>

  <p>
    We use <strong>inverse warping</strong> to avoid holes in the output image. 
    For each pixel in the output, its position is mapped backward using \( H^{-1} \) 
    to find the corresponding coordinates in the input image.
  </p>

  <p>
    Two interpolation methods were implemented from scratch:
  </p>

  <ul>
    <li><strong>Nearest Neighbor Interpolation:</strong> Each output pixel takes the value of the closest input pixel.</li>
    <li><strong>Bilinear Interpolation:</strong> Each output pixel is computed as a weighted average of its four neighboring input pixels.</li>
  </ul>

  <h3>Results and Discussion</h3>

  <p>
    The <em>Nearest Neighbor</em> interpolation ran faster 
    (<strong>1.46 seconds</strong>), but produced visible jagged edges along diagonal lines and object boundaries.  
    The <em>Bilinear</em> interpolation took longer (<strong>2.76 seconds</strong>), 
    yet yielded smoother transitions and overall better visual quality.
  </p>

  <p>
    Both methods successfully warped the images using inverse mapping, and we applied them for <strong>rectification</strong>. 
    For example, by selecting four corners of a rectangular region (such as a poster or a laptop screen) and 
    defining a perfect rectangle as the target coordinates, 
    the warped image was corrected so that the originally distorted rectangle appears truly rectangular.
  </p>

  <div class="row">
    <div class="img-block">
      <img src="macbook.jpg" alt="original macbook" width="300">
      <p>Original Image</p>
    </div>
    <div class="img-block">
      <img src="macbook_nearest_neighbor.jpg" alt="nearest neighbor" width="300">
      <p>Nearest Neighbor Result</p>
    </div>
    <div class="img-block">
      <img src="macbook_bilinear.jpg" alt="bilinear" width="300">
      <p>Bilinear Result</p>
    </div>
  </div>

  <div class="row">
    <div class="img-block">
      <img src="book.jpg" alt="original book" width="300">
      <p>Original Image</p>
    </div>
    <div class="img-block">
      <img src="book_nearest_neighbor.jpg" alt="book nearest neighbor" width="300">
      <p>Nearest Neighbor Result</p>
    </div>
    <div class="img-block">
      <img src="book_bilinear.jpg" alt="book bilinear" width="300">
      <p>Bilinear Result</p>
    </div>
  </div>
</div>

<!-- A.4 -->

<div class="section" id="A4">
  <h2>A.4: Blend the Images into a Mosaic</h2>

  <p>
    In this part, I combined multiple images into a single seamless mosaic using the computed homographies.  
    The left and right images were both warped into the coordinate system of the middle image, 
    so that all three images align in a common reference frame.
  </p>

  <p>
    After warping, I implemented two blending approaches to reduce visible seams:
  </p>

  <ul>
    <li><strong>Weighted Averaging (Alpha Feathering):</strong> 
      The alpha value is set to 1 at the center of each image and gradually falls to 0 near the edges, 
      based on the distance transform. This smooth transition helps avoid harsh boundaries between images.
    </li>
    <li><strong>Laplacian Pyramid Blending:</strong> 
      A multi-level blending method that combines images in both low and high frequency bands, 
      preserving edge details while minimizing ghosting artifacts. This produced smoother transitions and better color consistency.
    </li>
  </ul>

  <p>
    Since only eight pairs of correspondence points were selected and it was difficult to keep the phone perfectly centered during shooting, 
    some parts of the final mosaics are slightly misaligned and show mild ghosting.  
    Nonetheless, the overall alignment demonstrates that the homographies and blending pipeline worked as expected.
  </p>

  <div class="row">
    <div class="img-block">
      <img src="tower-mosaic_weighted.jpg" alt="tower weighted mosaic" width="400">
      <p>Weighted Averaging Mosaic (Tower)</p>
    </div>
    <div class="img-block">
      <img src="tower-mosaic_pyramid.jpg" alt="tower pyramid mosaic" width="400">
      <p>Laplacian Pyramid Mosaic (Tower)</p>
    </div>
  </div>

  <div class="row">
    <div class="img-block">
      <img src="library-mosaic_weighted.jpg" alt="library weighted mosaic" width="400">
      <p>Weighted Averaging Mosaic (Library)</p>
    </div>
    <div class="img-block">
      <img src="library-mosaic_pyramid.jpg" alt="library pyramid mosaic" width="400">
      <p>Laplacian Pyramid Mosaic (Library)</p>
    </div>
  </div>

  <div class="row">
    <div class="img-block">
      <img src="street-mosaic_weighted.jpg" alt="street weighted mosaic" width="400">
      <p>Weighted Averaging Mosaic (Street)</p>
    </div>
    <div class="img-block">
      <img src="street-mosaic_pyramid.jpg" alt="street pyramid mosaic" width="400">
      <p>Laplacian Pyramid Mosaic (Street)</p>
    </div>
  </div>
</div>

<!-- B.1 -->
    <div class="section" id="B1">
      <h2>B.1: Harris Corner Detection</h2>
      <p>
To detect feature points in an image, I first applied the <b>Harris Corner Detector</b>, 
which identifies pixels exhibiting strong intensity variations in both the x and y directions. <br><br>

Pixels with large Harris response values (R) are considered strong corner candidates. 
To avoid unstable detections at the borders, points near the image edges are discarded. <br><br>

While Harris corners effectively capture strong interest points, they often appear 
densely clustered in textured regions. To obtain a more balanced spatial distribution, 
I applied <b>Adaptive Non-Maximal Suppression (ANMS)</b>. 
This technique selects a subset of keypoints that are both strong and spatially well-separated. <br><br>

For each detected corner <i>i</i>, a suppression radius <i>r<sub>i</sub></i> is computed as the minimum distance 
to any other corner <i>j</i> that has a significantly higher Harris response:
</p>

<p style="text-align:center;">
  <i>
  r<sub>i</sub> = min<sub>j</sub> ||x<sub>i</sub> − x<sub>j</sub>|| , &nbsp;&nbsp;
  s.t. &nbsp; h<sub>j</sub> > c<sub>robust</sub> · h<sub>i</sub>
  </i>
</p>

<p>
Here, <i>h<sub>i</sub></i> is the Harris response of corner <i>i</i>, and 
<i>c<sub>robust</sub></i> is a robustness factor (set to 0.9 in our implementation). 
Each corner’s radius is inversely related to the density of stronger corners nearby. 
After computing all <i>r<sub>i</sub></i>, the algorithm keeps the 
<code>num_to_keep</code> corners with the largest radii, 
which represent the most spatially distinctive and well-distributed features.<br><br>

The following figures visualize the ANMS results (500 keypoints per image). 
Compared to the raw Harris corners shown previously, these keypoints 
are distributed more evenly across the image.
</p>

      <div class="row">
        <div class="img-block">
          <img src="harris_points.jpg" alt="Harris corners before ANMS" width="420">
          <p>Harris Corners (Before ANMS)</p>
        </div>
        <div class="img-block">
          <img src="anms_points.jpg" alt="Harris corners after ANMS" width="420">
          <p>Harris Corners (After ANMS)</p>
        </div>
      </div>
    </div>

<!-- B.2 -->
<div class="section" id="B2">
  <h2>B.2: Feature Descriptor Extraction</h2>

  <p>
    Each descriptor is formed from a <strong>blurred 40×40 window</strong> centered at the detected corner and then subsampled to an <strong>8×8</strong>
    patch. The patch is bias/gain normalized to reduce the effect of illumination differences.
  </p>

  <p><strong>Implementation details:</strong></p>

  <p><strong>Gaussian smoothing:</strong> The input image is first blurred with a Gaussian kernel (σ = 1.0) to reduce noise and produce a stable, smooth sampling field.</p>

  <p><strong>Patch extraction:</strong> For a corner at <em>(x<sub>i</sub>, y<sub>i</sub>)</em>, extract a <em>40 × 40</em> grayscale window centered at that coordinate.</p>

  <p><strong>Subsampling:</strong> Downsample the 40×40 window to an 8×8 patch. This creates a compact descriptor that captures coarse local structure while ignoring fine texture noise.</p>

  <p><strong>Bias/gain normalization:</strong> Normalize the 8×8 patch to remove illumination effects:</p>

  <div class="formula">I′ = (I − μ) / (σ + ε)</div>

  <p>
    where μ and σ are the patch mean and standard deviation, and ε is a small constant to avoid division by zero. These normalized descriptors are robust to linear changes in brightness and contrast.
  </p>

  <p>The figure below visualizes the top six Harris features and their corresponding 8×8 patches:</p>

  <div class="img-block" style="text-align: center;">
    <img src="harris_features_full.jpg" alt="Harris feature descriptors visualization" width="800">
    <p>Six extracted 8×8 feature descriptors of the strongest Harris corners.</p>
  </div>
</div>

<!-- B.3 -->
<div class="section" id="B3">
  <h2>B.3: Feature Matching</h2>

  <p>
    The feature matching process is based on the <strong>Lowe’s ratio test</strong>, which helps identify distinctive and reliable correspondences between two images.
  </p>

  <p><strong>Distance computation:</strong> For each descriptor d<sub>i</sub> in the first image, compute its Euclidean (L2) distance to all descriptors in the second image:</p>

  <div class="formula">d<sub>ij</sub> = || d<sub>i</sub> − d<sub>j</sub> ||<sup>2</sup></div>

  <p><strong>Nearest neighbor search:</strong> For each descriptor, find its two nearest neighbors d<sub>j</sub> and d<sub>k</sub> in the second image (the smallest and second-smallest distances).</p>

  <p><strong>Lowe’s ratio test:</strong> To reduce ambiguous matches, compute the ratio:</p>

  <div class="formula">ratio<sub>i</sub> = || d<sub>i</sub> − d<sub>j</sub> ||<sup>2</sup> / || d<sub>i</sub> − d<sub>k</sub> ||<sup>2</sup></div>

  <p>
    A match is accepted only if ratio<sub>i</sub> &lt; T, meaning the best match is significantly better than the next candidate.
    In this implementation, <strong>T = 0.3</strong> is used to ensure high-quality correspondences.
  </p>

  <p>
    This method ensures that the retained matches are both distinctive and robust, providing reliable correspondences between interest points across different images.
  </p>

  <div class="img-block" style="text-align: center;">
    <img src="matches_red_color.jpg" alt="Feature matching visualization" width="800">
    <p>Feature matching between two images.</p>
  </div>
</div>


<!-- B.4 -->
<div class="section" id="B4">
  <h2>B.4: RANSAC for Robust Homography</h2>

<p>
The RANSAC algorithm is used to estimate a robust homography matrix between two images. 
  It works by repeatedly selecting a small random subset of feature matches, computing a candidate homography, and then testing how many matches agree with that transformation (the inliers). 
  After many iterations, the model with the largest number of inliers is chosen as the best estimate, and a final homography is recalculated using all inlier points.
</p>

<p>
This process effectively removes outliers from the feature matching results, ensuring that only consistent correspondences are used.
  As a result, the final alignment between the two images becomes more accurate and stable.
</p>

<p>
Using RANSAC makes the image mosaic process more automated and reliable — we don’t have to manually pick corresponding points. 
  Combined with <b>Harris corner detection</b> for feature extraction, the matches are both accurate and efficient, leading to a clean and well-aligned mosaic.
    The results below compare mosaics created from <em>manual correspondences</em> (left) and 
    <em>automatically detected features with RANSAC</em> (right).
  </p>

  <!-- First Row -->
  <div class="row">
    <div class="img-block">
      <img src="tower-mosaic_pyramid.jpg" alt="Tower mosaic (manual)" width="400">
      <p>Manual (Tower)</p>
    </div>
    <div class="img-block">
      <img src="mosaic_auto.jpg" alt="Tower mosaic (auto RANSAC)" width="400">
      <p>Automatic with RANSAC (Tower)</p>
    </div>
  </div>

  <!-- Second Row -->
  <div class="row">
    <div class="img-block">
      <img src="library-mosaic_pyramid.jpg" alt="Library mosaic (manual)" width="400">
      <p>Manual (Library)</p>
    </div>
    <div class="img-block">
      <img src="library_3img.jpg" alt="Library mosaic (auto RANSAC)" width="400">
      <p>Automatic with RANSAC (Library)</p>
    </div>
  </div>

  <!-- Third Row -->
  <div class="row">
    <div class="img-block">
      <img src="street-mosaic_pyramid.jpg" alt="Street mosaic (manual)" width="400">
      <p>Manual (Street)</p>
    </div>
    <div class="img-block">
      <img src="street_3img.jpg" alt="Street mosaic (auto RANSAC)" width="400">
      <p>Automatic with RANSAC (Street)</p>
    </div>
  </div>
</div>


    
  </div>
</body>
</html>

